{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf41f95",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cac63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from preprocessing.text_cleaner import TextPreprocessor\n",
    "from reference_detection.detect_references import ReferenceDetector\n",
    "from analysis.similarity_analysis import SimilarityAnalyzer\n",
    "from analysis.concept_mapping import ConceptMapper\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf3cdcf",
   "metadata": {},
   "source": [
    "## 1. Reference Detection\n",
    "\n",
    "Detect how often Vedanta concepts, texts, and figures are mentioned in Anthroposophy texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector\n",
    "detector = ReferenceDetector()\n",
    "\n",
    "# Analyze Anthroposophy corpus\n",
    "anthro_dir = Path(\"../data/anthroposophy\")\n",
    "if anthro_dir.exists():\n",
    "    analysis = detector.analyze_corpus(anthro_dir)\n",
    "    \n",
    "    print(f\"Total Vedanta references found: {analysis['total_references']}\")\n",
    "    print(f\"Unique terms found: {analysis['unique_terms_across_corpus']}\")\n",
    "    print(\"\\nMost frequently mentioned terms:\")\n",
    "    for term, count in analysis['most_common_terms'][:10]:\n",
    "        print(f\"  {term:25s}: {count:3d}\")\n",
    "else:\n",
    "    print(\"No data found. Please run data collection first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reference frequencies\n",
    "if 'analysis' in locals():\n",
    "    terms = [t[0] for t in analysis['most_common_terms'][:15]]\n",
    "    counts = [t[1] for t in analysis['most_common_terms'][:15]]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(terms, counts, color='steelblue')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.title('Most Frequently Mentioned Vedanta Terms in Anthroposophy Texts')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0873cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize references by text file\n",
    "if 'analysis' in locals() and 'file_analyses' in analysis:\n",
    "    file_refs = [(file_data['filename'], file_data['total_references']) \n",
    "                 for file_data in analysis['file_analyses']]\n",
    "    file_refs.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    files = [f[0].replace('steiner_', '').replace('.txt', '').replace('_', ' ').title() \n",
    "             for f in file_refs]\n",
    "    refs = [f[1] for f in file_refs]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(range(len(files)), refs, color='teal', alpha=0.7)\n",
    "    plt.xticks(range(len(files)), files, rotation=45, ha='right')\n",
    "    plt.ylabel('Number of Vedanta References')\n",
    "    plt.title('Vedanta References by Anthroposophy Text')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, val) in enumerate(zip(bars, refs)):\n",
    "        if val > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, val + 0.3, str(val), \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bab977",
   "metadata": {},
   "source": [
    "### Context of References\n",
    "\n",
    "Let's look at where these references appear in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c0c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample contexts for most common terms\n",
    "if 'analysis' in locals() and 'file_analyses' in analysis:\n",
    "    print(\"Sample contexts for Vedanta references:\\n\")\n",
    "    \n",
    "    contexts_shown = 0\n",
    "    for file_data in analysis['file_analyses']:\n",
    "        if contexts_shown >= 5:  # Show 5 examples\n",
    "            break\n",
    "            \n",
    "        if file_data['total_references'] > 0:\n",
    "            filename = file_data['filename'].replace('steiner_', '').replace('.txt', '')\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"From: {filename.replace('_', ' ').title()}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            for match in file_data['matches'][:2]:  # Show up to 2 per file\n",
    "                if contexts_shown >= 5:\n",
    "                    break\n",
    "                print(f\"\\nTerm: '{match['term']}'\")\n",
    "                print(f\"Context: ...{match['context']}...\")\n",
    "                contexts_shown += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e3ef5",
   "metadata": {},
   "source": [
    "## 2. Text Similarity Analysis\n",
    "\n",
    "Compute semantic similarity between Anthroposophy and Vedanta texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba54e68",
   "metadata": {},
   "source": [
    "### Corpus Statistics\n",
    "\n",
    "Compare the size and characteristics of both text corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze corpus statistics\n",
    "import os\n",
    "\n",
    "anthro_dir = Path(\"../data/anthroposophy\")\n",
    "vedanta_dir = Path(\"../data/vedanta\")\n",
    "\n",
    "def get_text_stats(directory):\n",
    "    stats = []\n",
    "    for filepath in directory.glob(\"*.txt\"):\n",
    "        if filepath.name not in ['steiner_sample.txt', 'bhagavad_gita_sample.txt']:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                words = content.split()\n",
    "                stats.append({\n",
    "                    'filename': filepath.name.replace('.txt', '').replace('_', ' ').title(),\n",
    "                    'words': len(words),\n",
    "                    'chars': len(content),\n",
    "                    'lines': len(content.split('\\n'))\n",
    "                })\n",
    "    return stats\n",
    "\n",
    "anthro_stats = get_text_stats(anthro_dir)\n",
    "vedanta_stats = get_text_stats(vedanta_dir)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "df_anthro = pd.DataFrame(anthro_stats)\n",
    "df_vedanta = pd.DataFrame(vedanta_stats)\n",
    "\n",
    "print(\"ANTHROPOSOPHY CORPUS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total texts: {len(anthro_stats)}\")\n",
    "print(f\"Total words: {df_anthro['words'].sum():,}\")\n",
    "print(f\"Average words per text: {df_anthro['words'].mean():.0f}\")\n",
    "print(f\"\\nLargest text: {df_anthro.loc[df_anthro['words'].idxmax(), 'filename']}\")\n",
    "print(f\"             ({df_anthro['words'].max():,} words)\")\n",
    "\n",
    "print(\"\\n\\nVEDANTA CORPUS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total texts: {len(vedanta_stats)}\")\n",
    "print(f\"Total words: {df_vedanta['words'].sum():,}\")\n",
    "print(f\"Average words per text: {df_vedanta['words'].mean():.0f}\")\n",
    "print(f\"\\nLargest text: {df_vedanta.loc[df_vedanta['words'].idxmax(), 'filename']}\")\n",
    "print(f\"             ({df_vedanta['words'].max():,} words)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize text sizes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Anthroposophy\n",
    "df_anthro_sorted = df_anthro.sort_values('words', ascending=True)\n",
    "axes[0].barh(range(len(df_anthro_sorted)), df_anthro_sorted['words']/1000, color='cornflowerblue', alpha=0.8)\n",
    "axes[0].set_yticks(range(len(df_anthro_sorted)))\n",
    "axes[0].set_yticklabels([name[:35] for name in df_anthro_sorted['filename']], fontsize=9)\n",
    "axes[0].set_xlabel('Thousands of Words')\n",
    "axes[0].set_title('Anthroposophy Text Sizes', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Vedanta\n",
    "df_vedanta_sorted = df_vedanta.sort_values('words', ascending=True)\n",
    "axes[1].barh(range(len(df_vedanta_sorted)), df_vedanta_sorted['words']/1000, color='coral', alpha=0.8)\n",
    "axes[1].set_yticks(range(len(df_vedanta_sorted)))\n",
    "axes[1].set_yticklabels([name[:35] for name in df_vedanta_sorted['filename']], fontsize=9)\n",
    "axes[1].set_xlabel('Thousands of Words')\n",
    "axes[1].set_title('Vedanta Text Sizes', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = SimilarityAnalyzer(processed_dir=Path(\"../data/processed\"))\n",
    "\n",
    "# Load texts\n",
    "anthro_texts, vedanta_texts = analyzer.load_texts()\n",
    "\n",
    "print(f\"Loaded {len(anthro_texts)} Anthroposophy texts\")\n",
    "print(f\"Loaded {len(vedanta_texts)} Vedanta texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4848b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF similarity\n",
    "if len(anthro_texts) > 0 and len(vedanta_texts) > 0:\n",
    "    similarity_results = analyzer.compute_tfidf_similarity()\n",
    "    \n",
    "    print(f\"Average cross-corpus similarity: {similarity_results['average_similarity']:.4f}\")\n",
    "    print(f\"Maximum similarity: {similarity_results['max_similarity']:.4f}\")\n",
    "    print(f\"Minimum similarity: {similarity_results['min_similarity']:.4f}\")\n",
    "    \n",
    "    print(\"\\nMost similar text pairs:\")\n",
    "    for pair in similarity_results['most_similar_pairs'][:5]:\n",
    "        print(f\"  {pair['anthroposophy_text'][:40]:40s} <-> {pair['vedanta_text'][:40]:40s}: {pair['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity matrix\n",
    "if 'similarity_results' in locals():\n",
    "    similarity_matrix = np.array(similarity_results['similarity_matrix'])\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        similarity_matrix,\n",
    "        cmap='YlOrRd',\n",
    "        cbar_kws={'label': 'Cosine Similarity'}\n",
    "    )\n",
    "    plt.title('Anthroposophy vs Vedanta Text Similarity')\n",
    "    plt.xlabel('Vedanta Texts')\n",
    "    plt.ylabel('Anthroposophy Texts')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be844ab",
   "metadata": {},
   "source": [
    "## 3. Distinctive Terms Analysis\n",
    "\n",
    "Identify which terms are most characteristic of each tradition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract distinctive terms\n",
    "if hasattr(analyzer, 'tfidf_matrix') and analyzer.tfidf_matrix is not None:\n",
    "    distinctive_terms = analyzer.extract_distinctive_terms(top_n=20)\n",
    "    \n",
    "    print(\"Top Anthroposophy Terms:\")\n",
    "    for term_dict in distinctive_terms['anthroposophy_top_terms'][:10]:\n",
    "        print(f\"  {term_dict['term']:30s}: {term_dict['tfidf']:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop Vedanta Terms:\")\n",
    "    for term_dict in distinctive_terms['vedanta_top_terms'][:10]:\n",
    "        print(f\"  {term_dict['term']:30s}: {term_dict['tfidf']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distinctive terms\n",
    "if 'distinctive_terms' in locals():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Anthroposophy terms\n",
    "    anthro_terms = [t['term'] for t in distinctive_terms['anthroposophy_top_terms'][:15]]\n",
    "    anthro_scores = [t['tfidf'] for t in distinctive_terms['anthroposophy_top_terms'][:15]]\n",
    "    ax1.barh(anthro_terms, anthro_scores, color='cornflowerblue')\n",
    "    ax1.set_xlabel('TF-IDF Score')\n",
    "    ax1.set_title('Top Anthroposophy Terms')\n",
    "    \n",
    "    # Vedanta terms\n",
    "    vedanta_terms = [t['term'] for t in distinctive_terms['vedanta_top_terms'][:15]]\n",
    "    vedanta_scores = [t['tfidf'] for t in distinctive_terms['vedanta_top_terms'][:15]]\n",
    "    ax2.barh(vedanta_terms, vedanta_scores, color='coral')\n",
    "    ax2.set_xlabel('TF-IDF Score')\n",
    "    ax2.set_title('Top Vedanta Terms')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491e144",
   "metadata": {},
   "source": [
    "## 4. Topic Modeling\n",
    "\n",
    "Discover latent topics across both corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb027e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform topic modeling\n",
    "if len(anthro_texts) > 0 and len(vedanta_texts) > 0:\n",
    "    topic_results = analyzer.perform_topic_modeling(n_topics=8)\n",
    "    \n",
    "    print(\"Discovered Topics:\\n\")\n",
    "    for topic in topic_results['topics']:\n",
    "        print(f\"Topic {topic['topic_id']}: {', '.join(topic['top_words'][:8])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da27e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare topic distributions\n",
    "if 'topic_results' in locals():\n",
    "    topics = [f\"Topic {i}\" for i in range(len(topic_results['topics']))]\n",
    "    anthro_dist = topic_results['anthroposophy_topic_distribution']\n",
    "    vedanta_dist = topic_results['vedanta_topic_distribution']\n",
    "    \n",
    "    x = np.arange(len(topics))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width/2, anthro_dist, width, label='Anthroposophy', color='cornflowerblue')\n",
    "    ax.bar(x + width/2, vedanta_dist, width, label='Vedanta', color='coral')\n",
    "    \n",
    "    ax.set_xlabel('Topics')\n",
    "    ax.set_ylabel('Average Proportion')\n",
    "    ax.set_title('Topic Distribution by Tradition')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(topics, rotation=45)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766001f4",
   "metadata": {},
   "source": [
    "### Word Clouds\n",
    "\n",
    "Generate word clouds to visualize the most prominent vocabulary in each tradition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d258f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install wordcloud if needed\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    \n",
    "    # Load and combine texts\n",
    "    def load_corpus_text(directory):\n",
    "        all_text = []\n",
    "        for filepath in directory.glob(\"*.txt\"):\n",
    "            if filepath.name not in ['steiner_sample.txt', 'bhagavad_gita_sample.txt']:\n",
    "                with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                    all_text.append(f.read().lower())\n",
    "        return ' '.join(all_text)\n",
    "    \n",
    "    anthro_text = load_corpus_text(anthro_dir)\n",
    "    vedanta_text = load_corpus_text(vedanta_dir)\n",
    "    \n",
    "    # Create word clouds\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Anthroposophy word cloud\n",
    "    wordcloud_anthro = WordCloud(\n",
    "        width=800, height=400, \n",
    "        background_color='white',\n",
    "        colormap='Blues',\n",
    "        max_words=100,\n",
    "        stopwords=set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'what', 'which', 'who', 'when', 'where', 'why', 'how', 'not', 'no', 'nor', 'so', 'than', 'too', 'very', 'just', 'as', 'from', 'up', 'about', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'between', 'under', 'again', 'further', 'then', 'once'])\n",
    "    ).generate(anthro_text)\n",
    "    \n",
    "    axes[0].imshow(wordcloud_anthro, interpolation='bilinear')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Anthroposophy Vocabulary', fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Vedanta word cloud\n",
    "    wordcloud_vedanta = WordCloud(\n",
    "        width=800, height=400,\n",
    "        background_color='white',\n",
    "        colormap='Oranges',\n",
    "        max_words=100,\n",
    "        stopwords=set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'what', 'which', 'who', 'when', 'where', 'why', 'how', 'not', 'no', 'nor', 'so', 'than', 'too', 'very', 'just', 'as', 'from', 'up', 'about', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'between', 'under', 'again', 'further', 'then', 'once'])\n",
    "    ).generate(vedanta_text)\n",
    "    \n",
    "    axes[1].imshow(wordcloud_vedanta, interpolation='bilinear')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Vedanta Vocabulary', fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Word clouds generated successfully\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"WordCloud library not installed. Run: pip install wordcloud\")\n",
    "    print(\"Skipping word cloud visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02462f62",
   "metadata": {},
   "source": [
    "### Term Co-occurrence Network\n",
    "\n",
    "Visualize which Vedanta terms appear together in Anthroposophy texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b28f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build term co-occurrence network\n",
    "if 'analysis' in locals() and 'file_analyses' in analysis:\n",
    "    try:\n",
    "        import networkx as nx\n",
    "        \n",
    "        # Build co-occurrence matrix\n",
    "        from collections import defaultdict\n",
    "        cooccurrence = defaultdict(int)\n",
    "        \n",
    "        for file_data in analysis['file_analyses']:\n",
    "            terms_in_file = [m['term'] for m in file_data['matches']]\n",
    "            # Count co-occurrences (terms appearing in same text)\n",
    "            for i, term1 in enumerate(terms_in_file):\n",
    "                for term2 in terms_in_file[i+1:]:\n",
    "                    pair = tuple(sorted([term1, term2]))\n",
    "                    cooccurrence[pair] += 1\n",
    "        \n",
    "        # Create network graph\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Add edges with weights\n",
    "        for (term1, term2), weight in cooccurrence.items():\n",
    "            if weight >= 2:  # Only show terms that co-occur at least twice\n",
    "                G.add_edge(term1, term2, weight=weight)\n",
    "        \n",
    "        if len(G.nodes()) > 0:\n",
    "            # Calculate node sizes based on degree\n",
    "            node_sizes = [300 + G.degree(node) * 200 for node in G.nodes()]\n",
    "            \n",
    "            # Draw network\n",
    "            plt.figure(figsize=(14, 10))\n",
    "            pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "            \n",
    "            # Draw edges with varying thickness\n",
    "            edges = G.edges()\n",
    "            weights = [G[u][v]['weight'] for u, v in edges]\n",
    "            \n",
    "            nx.draw_networkx_edges(G, pos, alpha=0.3, width=[w*0.5 for w in weights])\n",
    "            nx.draw_networkx_nodes(G, pos, node_size=node_sizes, \n",
    "                                 node_color='lightblue', alpha=0.8, \n",
    "                                 edgecolors='navy', linewidths=2)\n",
    "            nx.draw_networkx_labels(G, pos, font_size=10, font_weight='bold')\n",
    "            \n",
    "            plt.title('Vedanta Term Co-occurrence Network in Anthroposophy Texts', \n",
    "                     fontsize=14, fontweight='bold', pad=20)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"Network contains {len(G.nodes())} terms and {len(G.edges())} co-occurrence relationships\")\n",
    "        else:\n",
    "            print(\"Not enough co-occurrences to build network (need at least 2 shared appearances)\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"NetworkX library not installed. Run: pip install networkx\")\n",
    "        print(\"Skipping network visualization.\")\n",
    "else:\n",
    "    print(\"No reference analysis data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606c236",
   "metadata": {},
   "source": [
    "## 5. Concept Mapping\n",
    "\n",
    "Map parallel concepts between the two traditions using semantic embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdf05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize concept mapper\n",
    "mapper = ConceptMapper()\n",
    "\n",
    "# Find parallel concepts\n",
    "if mapper.model:\n",
    "    mappings = mapper.find_parallel_concepts(top_n=3)\n",
    "    \n",
    "    print(\"Concept Mappings:\\n\")\n",
    "    for mapping in mappings[:5]:\n",
    "        print(f\"\\n{mapping['anthroposophy_concept'].upper()}\")\n",
    "        print(f\"  ({mapping['anthroposophy_description']})\")\n",
    "        print(\"  Most similar Vedanta concepts:\")\n",
    "        for match in mapping['top_matches'][:3]:\n",
    "            print(f\"    • {match['vedanta_concept']} (similarity: {match['similarity']:.3f})\")\n",
    "else:\n",
    "    print(\"Sentence transformers not available. Install with: pip install sentence-transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65986c20",
   "metadata": {},
   "source": [
    "## 6. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'analysis' in locals():\n",
    "    print(f\"\\n1. REFERENCE DETECTION\")\n",
    "    print(f\"   Total Vedanta references in Anthroposophy texts: {analysis.get('total_references', 0)}\")\n",
    "    print(f\"   Unique Vedanta terms found: {analysis.get('unique_terms_across_corpus', 0)}\")\n",
    "\n",
    "if 'similarity_results' in locals():\n",
    "    print(f\"\\n2. SEMANTIC SIMILARITY\")\n",
    "    print(f\"   Average text similarity: {similarity_results['average_similarity']:.4f}\")\n",
    "    print(f\"   Maximum similarity: {similarity_results['max_similarity']:.4f}\")\n",
    "\n",
    "if 'topic_results' in locals():\n",
    "    print(f\"\\n3. TOPIC MODELING\")\n",
    "    print(f\"   Number of topics discovered: {topic_results['n_topics']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4a5e3",
   "metadata": {},
   "source": [
    "### Advanced Visualizations\n",
    "\n",
    "Additional comparative charts and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881735af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative pie chart of term categories\n",
    "if 'analysis' in locals() and 'most_common_terms' in analysis:\n",
    "    # Categorize terms\n",
    "    categories = {\n",
    "        'Texts & Scriptures': ['gita', 'vedas', 'upanishads', 'bhagavad'],\n",
    "        'Concepts & Philosophy': ['maya', 'karma', 'dharma', 'brahman', 'atman', 'moksha'],\n",
    "        'Practices': ['yoga', 'meditation', 'self-knowledge'],\n",
    "        'Figures': ['krishna', 'vivekananda', 'shankara', 'vedanta']\n",
    "    }\n",
    "    \n",
    "    category_counts = {cat: 0 for cat in categories}\n",
    "    \n",
    "    for term, count in analysis['most_common_terms']:\n",
    "        for category, terms in categories.items():\n",
    "            if any(t in term.lower() for t in terms):\n",
    "                category_counts[category] += count\n",
    "                break\n",
    "    \n",
    "    # Remove empty categories\n",
    "    category_counts = {k: v for k, v in category_counts.items() if v > 0}\n",
    "    \n",
    "    if category_counts:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Pie chart\n",
    "        colors = plt.cm.Set3(range(len(category_counts)))\n",
    "        wedges, texts, autotexts = ax1.pie(\n",
    "            category_counts.values(), \n",
    "            labels=category_counts.keys(),\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            colors=colors\n",
    "        )\n",
    "        ax1.set_title('Vedanta References by Category', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Bar chart with category breakdown\n",
    "        ax2.bar(range(len(category_counts)), category_counts.values(), \n",
    "               color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "        ax2.set_xticks(range(len(category_counts)))\n",
    "        ax2.set_xticklabels(category_counts.keys(), rotation=45, ha='right')\n",
    "        ax2.set_ylabel('Number of References')\n",
    "        ax2.set_title('Reference Count by Category', fontsize=12, fontweight='bold')\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (cat, val) in enumerate(category_counts.items()):\n",
    "            ax2.text(i, val + 0.3, str(val), ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Not enough data to categorize terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afedf89",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_dir = Path(\"../results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if 'similarity_results' in locals():\n",
    "    with open(results_dir / \"similarity_results.json\", 'w') as f:\n",
    "        json.dump(similarity_results, f, indent=2)\n",
    "    print(\"Saved similarity results\")\n",
    "\n",
    "if 'distinctive_terms' in locals():\n",
    "    with open(results_dir / \"distinctive_terms.json\", 'w') as f:\n",
    "        json.dump(distinctive_terms, f, indent=2)\n",
    "    print(\"Saved distinctive terms\")\n",
    "\n",
    "if 'topic_results' in locals():\n",
    "    with open(results_dir / \"topic_results.json\", 'w') as f:\n",
    "        json.dump(topic_results, f, indent=2)\n",
    "    print(\"Saved topic modeling results\")\n",
    "\n",
    "print(\"\\nAll results exported to:\", results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32039c01",
   "metadata": {},
   "source": [
    "### Save Visualizations\n",
    "\n",
    "Export key visualizations as image files for reports and presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures directory\n",
    "figures_dir = Path(\"../results/figures\")\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "saved_figures = []\n",
    "\n",
    "# Function to save current figure\n",
    "def save_current_figure(filename, dpi=300):\n",
    "    filepath = figures_dir / filename\n",
    "    plt.savefig(filepath, dpi=dpi, bbox_inches='tight', facecolor='white')\n",
    "    saved_figures.append(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"To save visualizations, re-run the visualization cells above and then execute:\")\n",
    "print()\n",
    "print(\"# After each visualization:\")\n",
    "print(\"save_current_figure('reference_frequency.png')\")\n",
    "print(\"save_current_figure('references_by_text.png')\")\n",
    "print(\"save_current_figure('text_sizes_comparison.png')\")\n",
    "print(\"save_current_figure('similarity_heatmap.png')\")\n",
    "print(\"save_current_figure('distinctive_terms.png')\")\n",
    "print(\"save_current_figure('topic_distributions.png')\")\n",
    "print(\"save_current_figure('wordclouds.png')\")\n",
    "print(\"save_current_figure('cooccurrence_network.png')\")\n",
    "print(\"save_current_figure('category_breakdown.png')\")\n",
    "print()\n",
    "print(f\"Figures will be saved to: {figures_dir.absolute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
